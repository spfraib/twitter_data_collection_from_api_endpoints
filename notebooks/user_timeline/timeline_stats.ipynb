{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e85b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7984eeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Date:',datetime.today().strftime('%d%m%Y'))\n",
    "spark = SparkSession.builder.config(\"spark.sql.files.ignoreCorruptFiles\",\"true\") .config(\"spark.serializer\",\"org.apache.spark.serializer.KryoSerializer\") .config(\"spark.yarn.appMasterEnv.LANG\",\"en_US.UTF-8\") .config(\"spark.executorEnv.LANG\",\"en_US.UTF-8\") .config(\"spark.driver.extraJavaOptions\",\"-Duser.timezone=UTC\") .config(\"spark.executor.extraJavaOptions\",\"-Duser.timezone=UTC\") .config(\"spark.sql.session.timeZone\",\"UTC\") .config(\"spark.hadoop.dfs.replication\",\"1\") .config(\"spark.sql.broadcastTimeout\",-1) .getOrCreate()\n",
    "print(spark.sparkContext.getConf().getAll())\n",
    "path_to_data = \"/user/spf248/twitter_data_collection/data\"\n",
    "print(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732d1f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(country_short):\n",
    "    users_in_country = profiles.where(profiles['country_short']==country_short).select(\"user_id\")\n",
    "    snowball_in_country = timelines.join(F.broadcast(users_in_country),on='user_id')\n",
    "    snowball_in_country = snowball_in_country.withColumn(\"snowball_id\",F.explode(\"tweet_mentioned_user_id\")).drop('tweet_mentioned_user_id')\n",
    "    snowball_in_country = snowball_in_country.join(F.broadcast(users_in_country.withColumnRenamed('user_id','snowball_id')),on='snowball_id').drop_duplicates()\n",
    "    print(\"Snowball list\",snowball_in_country.cache().count())\n",
    "    seeds_in_country = seeds.join(users_in_country,on='user_id')\n",
    "    print(\"# Seeds in country\",seeds_in_country.cache().count())\n",
    "    snowball_1 = snowball_in_country.join(F.broadcast(seeds_in_country),on='user_id').join(seeds_in_country.withColumnRenamed('user_id','snowball_id'),on='snowball_id',how='left_anti').selectExpr('snowball_id as user_id').distinct()\n",
    "    snowball_2 = snowball_in_country.join(F.broadcast(snowball_1),on='user_id').join(seeds_in_country.unionByName(snowball_1).withColumnRenamed('user_id','snowball_id'),on='snowball_id',how='left_anti').selectExpr('snowball_id as user_id').distinct()\n",
    "    snowball_3 = snowball_in_country.join(F.broadcast(snowball_2),on='user_id').join(seeds_in_country.unionByName(snowball_1).unionByName(snowball_2).withColumnRenamed('user_id','snowball_id'),on='snowball_id',how='left_anti').selectExpr('snowball_id as user_id').distinct()\n",
    "    snowball_4 = snowball_in_country.join(F.broadcast(snowball_3),on='user_id').join(seeds_in_country.unionByName(snowball_1).unionByName(snowball_2).unionByName(snowball_3).withColumnRenamed('user_id','snowball_id'),on='snowball_id',how='left_anti').selectExpr('snowball_id as user_id').distinct()\n",
    "    stats = spark.createDataFrame([{\n",
    "    'n_seeds': seeds_in_country.count(), \n",
    "    'n_snowball_1': snowball_1.count(), \n",
    "    'n_snowball_2': snowball_2.count(), \n",
    "    'n_snowball_3': snowball_3.count(), \n",
    "    'n_snowball_4': snowball_4.count(), \n",
    "    }])\n",
    "    stats.write.mode(\"overwrite\").parquet(os.path.join(path_to_data,\"preprocessing\",\"stats\",country_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91549bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "timelines = spark.read.parquet(os.path.join(path_to_data,\"user_timeline\",\"extract\")).select(\"user_id\",\"tweet_mentioned_user_id\")\n",
    "locations = spark.read.parquet(os.path.join(path_to_data,\"preprocessed\",\"locations\",\"locations_geocoded.parquet\")).select(\"user_location\",\"country_short\")\n",
    "profiles = spark.read.parquet(os.path.join(path_to_data,\"user_timeline\",\"profiles\")).select(\"user_id\",\"country_short\")\n",
    "seeds = spark.read.parquet(os.path.join(path_to_data,\"lookup_users\",\"seeds\"))\n",
    "get_stats(\"NG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
