{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "from datetime import date\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "from glob import glob\n",
    "import json\n",
    "import tweepy\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today: 27102022\n",
      "cutoff: 100000\n",
      "path_to_data: /scratch/spf248/twitter_data_collection/data\n",
      "id_type: user_id\n",
      "max_users_per_app: 60\n"
     ]
    }
   ],
   "source": [
    "today = date.today().strftime('%d%m%Y')\n",
    "cutoff = 100000\n",
    "path_to_data = \"/scratch/spf248/twitter_data_collection/data\"\n",
    "id_type = 'user_id'\n",
    "max_users_per_app = 60\n",
    "apps = ['spfraib_sentiments','WorldBankGroup6'] # ['spfraib_sentiments','WorldBankGroup6']\n",
    "\n",
    "print('today:',today)\n",
    "print('cutoff:',cutoff)\n",
    "print('path_to_data:',path_to_data)\n",
    "print('id_type:',id_type)\n",
    "print('max_users_per_app:',max_users_per_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key files: 73\n"
     ]
    }
   ],
   "source": [
    "def select_key_files(path_to_data,max_users_per_app,apps):\n",
    "    key_files = []\n",
    "    key_usernames = []\n",
    "    app2username = {}\n",
    "    all_files = sorted(glob(os.path.join(path_to_data,'../keys','v1','*.json')))\n",
    "    for file in all_files:\n",
    "        username = file.split('/')[-1].split('-')[1].split('.json')[0]\n",
    "        app = file.split('/')[-1].split('-')[0]\n",
    "        app2username.setdefault(app, [])\n",
    "        if app in apps and username not in key_usernames and len(app2username[app])<max_users_per_app:\n",
    "            app2username[app].append(username)\n",
    "            key_files.append(file)\n",
    "            key_usernames.append(username)\n",
    "    return key_files\n",
    "\n",
    "key_files = select_key_files(path_to_data,max_users_per_app,apps)\n",
    "print('key files:', len(key_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLURM_JOB_ID : 26178559\n",
      "SLURM_ARRAY_TASK_COUNT : 73 (Default)\n",
      "SLURM_ARRAY_TASK_ID : 0 (Default)\n"
     ]
    }
   ],
   "source": [
    "def get_env_var(varname,default):\n",
    "    if os.environ.get(varname) != None:\n",
    "        var = int(os.environ.get(varname))\n",
    "        print(varname,':', var)\n",
    "    else:\n",
    "        var = default\n",
    "        print(varname,':', var,'(Default)')\n",
    "    return var\n",
    "\n",
    "# Choose Number of Nodes To Distribute Credentials: e.g. jobarray=0-4, cpu_per_task=20, credentials = 90 (<100)\n",
    "SLURM_JOB_ID            = get_env_var('SLURM_JOB_ID',0)\n",
    "SLURM_ARRAY_TASK_COUNT  = get_env_var('SLURM_ARRAY_TASK_COUNT',len(key_files))\n",
    "SLURM_ARRAY_TASK_ID     = get_env_var('SLURM_ARRAY_TASK_ID',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load users:\n",
      "# users_batch: 1703768\n",
      "Computing Time: 1 sec\n"
     ]
    }
   ],
   "source": [
    "print('Load users:')\n",
    "start = timer()\n",
    "files = pd.Series(sorted(glob(os.path.join(path_to_data,\"lookup_users\",\"batch\",\"*.parquet\")))).sample(frac=1,random_state=0).to_list()\n",
    "files_node = list(np.array_split(files,SLURM_ARRAY_TASK_COUNT)[SLURM_ARRAY_TASK_ID])\n",
    "users = pd.read_parquet(files_node)['user_id']\n",
    "print('# users_batch:', len(users))\n",
    "end = timer()\n",
    "print('Computing Time:', round(end - start), 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# keys: 73\n",
      "key file: /scratch/spf248/twitter_data_collection/data/../keys/v1/WorldBankGroup6-aleister.json\n"
     ]
    }
   ],
   "source": [
    "def get_key_file(key_files,SLURM_ARRAY_TASK_ID,SLURM_ARRAY_TASK_COUNT):\n",
    "    print('# keys:', len(key_files))\n",
    "    if SLURM_ARRAY_TASK_COUNT!=len(key_files) or SLURM_ARRAY_TASK_ID>=len(key_files) or SLURM_ARRAY_TASK_ID<0:\n",
    "        print(\"CHECK JOBARRAY\")\n",
    "    return key_files[SLURM_ARRAY_TASK_ID]\n",
    "        \n",
    "key_file = get_key_file(key_files,SLURM_ARRAY_TASK_ID,SLURM_ARRAY_TASK_COUNT)\n",
    "print('key file:', key_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_API_auth(key_file):\n",
    "    # Import Key\n",
    "    with open(key_file) as f:\n",
    "        key = json.load(f)\n",
    "    # OAuth process, using the keys and tokens\n",
    "    auth = tweepy.OAuthHandler(key['consumer_key'], key['consumer_secret'])\n",
    "    auth.set_access_token(key['access_token'], key['access_token_secret'])\n",
    "    # Creation of the actual interface, using authentication\n",
    "    api_auth = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "    try:\n",
    "        api_auth.verify_credentials()\n",
    "    except:\n",
    "        sys.exit(key_file,\": error during authentication\")\n",
    "    return api_auth\n",
    "\n",
    "# for key_file in glob(os.path.join(path_to_data,'../keys','v1','*.json')):\n",
    "#     get_API_auth(key_file)\n",
    "# print('Credentials Checked!')\n",
    "\n",
    "# Create API auth\n",
    "api = get_API_auth(key_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Chunks: 17038\n"
     ]
    }
   ],
   "source": [
    "# Create a function called \"chunks\" with two arguments, l and n:\n",
    "def chunks(l, n):\n",
    "    # For item i in a range that is a length of l,\n",
    "    for i in range(0, len(l), n):\n",
    "        # Create an index range for l of n items:\n",
    "        yield l[i:i+n]\n",
    "        \n",
    "# Split users by chunks of size 100 to accomodate Twitter lookup limit\n",
    "users_chunks = list(chunks(list(users),100))\n",
    "print(\"# Chunks:\", len(users_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_users(api,users,id_type='user_id'):\n",
    "    # Lookup users by chunks of size 100\n",
    "    if len(users)>100:\n",
    "        print('Reduce # Users')\n",
    "        return []\n",
    "    try:\n",
    "        if id_type=='user_id':\n",
    "            lookups = api.lookup_users(user_id=list(users),include_entities='true',tweet_mode='extended')\n",
    "        elif id_type=='screen_name':\n",
    "            lookups = api.lookup_users(screen_name=list(users),include_entities='true',tweet_mode='extended')\n",
    "        return [lookup._json for lookup in lookups]\n",
    "    except tweepy.errors.TweepyException as e:\n",
    "        print('Lookup error', e)\n",
    "        return []\n",
    "    \n",
    "# print('Lookup Users...\\n')\n",
    "# start = timer()\n",
    "# lookups = lookup_users(get_API_auth(key_file), users_chunks[0], 'user_id')\n",
    "# end = timer()\n",
    "# print('Computing Time:', round(end - start), 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookup Users...\n",
      "\n",
      "Data up to block 0 with 13 users stored in file lookup_users_13_27102022_26178559_0_507c4c49-d0c0-4cfe-b274-1c2bd066e6e9.json\n",
      "Computing Time: 30 sec\n"
     ]
    }
   ],
   "source": [
    "print('Lookup Users...\\n')\n",
    "start = timer()\n",
    "# Initialize Output File ID\n",
    "output_id = str(uuid.uuid4())\n",
    "# Initialize Output Data\n",
    "lookups = []\n",
    "for i_chunk,users_chunk in enumerate(users_chunks):\n",
    "    lookups.extend(lookup_users(api,users_chunk,id_type))\n",
    "    if i_chunk and not i_chunk%100:\n",
    "        print(\"# blocks:\",i_chunk)\n",
    "        print(\"# lookups:\",len(lookups))\n",
    "    if len(lookups)>=cutoff or i_chunk==len(users_chunks)-1:\n",
    "        filename = 'lookup_users_'+str(len(lookups))+'_'+today+'_'+str(SLURM_JOB_ID)+'_'+str(SLURM_ARRAY_TASK_ID)+'_'+output_id+'.json'\n",
    "        print('Data up to block',i_chunk,'with',len(lookups),'users stored in file',filename)\n",
    "        os.makedirs(os.path.join(path_to_data,'lookup_users','API',today),exist_ok=True)\n",
    "        pd.DataFrame(lookups).to_json(\n",
    "        os.path.join(path_to_data,'lookup_users','API',today,filename),\n",
    "        orient='records',\n",
    "        force_ascii=False,\n",
    "        date_format=None,\n",
    "        double_precision=15)\n",
    "        end = timer()\n",
    "        print('Computing Time:', round(end - start), 'sec')\n",
    "        # Reset\n",
    "        start = timer()\n",
    "        output_id = str(uuid.uuid4())\n",
    "        lookups = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
